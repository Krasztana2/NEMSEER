{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at 5-minute pre-dispatch demand forecast errors in 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will take a look at 5-minute pre-dispatch ({term}`5MPD`) demand forecast \"error\" (the difference between actual and forecasted demand) for 2021. AEMO runs {term}`5MPD` to provide system and market information for the next hour.\n",
    "\n",
    "We'll look at forecast \"error\" on a NEM-wide basis; that is, we will sum actual scheduled demand across all NEM regions and then compare that to the sum of forecast scheduled demand across all NEM regions. \n",
    "\n",
    "The code below could be modified to do this analysis on a region by region basis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libraries\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pathlib import Path\n",
    "import multiprocessing as mp\n",
    "\n",
    "# NEM data libraries\n",
    "# NEMOSIS for actual demand data\n",
    "# NEMSEER for forecast demand data\n",
    "import nemosis\n",
    "from nemseer import compile_data, download_raw_data, generate_runtimes\n",
    "from nemseer.data import DATETIME_FORMAT\n",
    "\n",
    "# data wrangling libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# interactive plotting\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "# progress bar for error computation\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "# supress logging from NEMSEER and NEMOSIS\n",
    "import logging\n",
    "\n",
    "logging.getLogger(\"nemosis\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"nemseer\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining our analysis start and end dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_start = \"2021/01/01 00:05:00\"\n",
    "analysis_end = \"2022/01/01 00:00:00\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining actual demand data from `NEMOSIS`\n",
    "\n",
    "We will download `DISPATCHREGIONSUM` to access the `TOTALDEMAND` field (actual scheduled demand).\n",
    "\n",
    "We'll first download the data we need and cache it so that it's ready for computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nemosis_cache = Path(\"nemosis_cache/\")\n",
    "if not nemosis_cache.exists():\n",
    "    nemosis_cache.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "nemosis.cache_compiler(\n",
    "    analysis_start, analysis_end, \"DISPATCHREGIONSUM\", nemosis_cache, fformat=\"parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining forecast demand data from `NEMSEER`\n",
    "\n",
    "We will download `REGIONSOLUTION` to access the `TOTALDEMAND` field in `P5MIN` forecasts.\n",
    "\n",
    "We'll first download the data we need and cache it so that it's ready for computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "download_raw_data(\n",
    "    \"P5MIN\",\n",
    "    \"REGIONSOLUTION\",\n",
    "    \"nemseer_cache/\",\n",
    "    forecasted_start=analysis_start,\n",
    "    forecasted_end=analysis_end,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating forecast error\n",
    "\n",
    "Below we calculate demand forecast error for `P5MIN` forecasts using forecast demand data and actual demand data. \n",
    "\n",
    "```{attention}\n",
    "\n",
    "The {term}`actual run time` of 5MPD is approximately 5 minutes before the nominal {term}`run time`. We will adjust for this in this when calculating forecast ahead times. See the note in {ref}`this section <quick_start:core concepts and information for users>`.\n",
    "```\n",
    "\n",
    "We provide two methods below:\n",
    "\n",
    "1. A **simpler** implementation that uses handy functionalities from both `xarray` and `pandas`. This implementation is a quick and simple way to compute demand forecast error for a couple of forecasted intervals. Though we provide a way to compute error over a longer period (e.g. a year), you should use the next method to compute error unless RAM/memory is a limiting factor (though it should be noted that whilst using `multiprocessing` with this method will speed things up, it will consume more memory).\n",
    "\n",
    "2. A **vectorised**, pure-`pandas` implementation. This implementation requires more lines of `pandas` code, but is much faster and preferable to the first implementation if you are computing error across a longer period (e.g. a year). However, as data for the entire period is loaded into memory, adapt the length of the period you select to your machine specifications (e.g. a year's worth of forecast data consumed ~15GB on the test machine)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `xarray` + `pandas` implementation (simpler code)\n",
    "\n",
    "The code below uses functionalities offered by `NEMOSIS`, `NEMSEER` and `xarray` to simplify coding effort. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_p5min_demand_forecast_error_simpler(forecasted_time: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculates P5MIN demand forecast error (Actual - Forecast) for all forecasts\n",
    "    that are run for a given forecasted_time.\n",
    "\n",
    "    Args:\n",
    "        forecasted_time: Datetime string in the form YYYY/mm/dd HH:MM:SS\n",
    "    Returns:\n",
    "        pandas DataFrame with forecast error in `TOTALDEMAND` columns, the ahead time\n",
    "        of the forecast run in `ahead_time`, and the forecasted time in\n",
    "        `forecasted_time`.\n",
    "    \"\"\"\n",
    "    # necessary for datetime indexing with pandas and xarray\n",
    "    time = str(forecasted_time).replace(\"-\", \"/\")\n",
    "    # get forecast data for forecasted_time\n",
    "    run_start, run_end = generate_runtimes(time, time, \"P5MIN\")\n",
    "    nemseer_data = compile_data(\n",
    "        run_start,\n",
    "        run_end,\n",
    "        time,\n",
    "        time,\n",
    "        \"P5MIN\",\n",
    "        \"REGIONSOLUTION\",\n",
    "        \"nemseer_cache/\",\n",
    "        data_format=\"xr\",\n",
    "    )\n",
    "    demand_forecasts = nemseer_data[\"REGIONSOLUTION\"][\"TOTALDEMAND\"]\n",
    "    # get actual demand data for forecasted_time\n",
    "    # nemosis start time must precede end of interval of interest by 5 minutes\n",
    "    nemosis_start = (\n",
    "        datetime.strptime(time, \"%Y/%m/%d %H:%M:%S\") - timedelta(minutes=5)\n",
    "    ).strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "    # compile data using nemosis, using cached parquet and filtering out interventions\n",
    "    nemosis_data = nemosis.dynamic_data_compiler(\n",
    "        nemosis_start,\n",
    "        time,\n",
    "        \"DISPATCHREGIONSUM\",\n",
    "        nemosis_cache,\n",
    "        filter_cols=[\"INTERVENTION\"],\n",
    "        filter_values=([0],),\n",
    "        fformat=\"parquet\",\n",
    "    )\n",
    "    # sum actual demand across regions\n",
    "    actual_demand = nemosis_data.groupby(\"SETTLEMENTDATE\")[\"TOTALDEMAND\"].sum()[time]\n",
    "    # sum forecast demand across regions\n",
    "    query_forecasts = demand_forecasts.sum(dim=\"REGIONID\").sel(forecasted_time=time)\n",
    "    # calculate error and return as a pandas DataFrame\n",
    "    error = (actual_demand - query_forecasts).to_dataframe()\n",
    "    # calculate number of minutes ahead, but adjust for nominal vs actual run time of P5MIN\n",
    "    error[\"ahead_time\"] = error[\"forecasted_time\"] - (\n",
    "        error.index - timedelta(minutes=5)\n",
    "    )\n",
    "    error = error.set_index(\"forecasted_time\")\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing error across 2021\n",
    "\n",
    "```{caution}\n",
    "While this code demonstrates how you could use the `pandas` + `xarray` implementation to compute error across a year, we only provide this as an example. We recommend you use the vectorised implementation if your system memory permits.\n",
    "```\n",
    "\n",
    "Because we haven't optimised our code, it will take a while to calculate forecast error across a year.\n",
    "\n",
    "To speed up computation, we will use Python's [`multiprocessing`](https://docs.python.org/3/library/multiprocessing.html) module. In this example, we use 10 simultaneous processes.\n",
    "\n",
    "`tqdm` provides us with a progress bar that shows us how many iterations are being completed in a second, as well as the progress over all intervals in the year or interest.\n",
    "\n",
    "Results DataFrames are added to a list as processes finish computation. Once they've finished, we can then concatenate these DataFrames to get a forecast error DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f5274c865a4caf86fa7b3b76a527bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "times = pd.date_range(analysis_start, analysis_end, freq=\"5T\")\n",
    "with mp.Pool(10) as p:\n",
    "    results = list(\n",
    "        tqdm(\n",
    "            p.imap(calculate_p5min_demand_forecast_error_simpler, times),\n",
    "            total=len(times),\n",
    "        )\n",
    "    )\n",
    "forecast_error = pd.concat(results, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pure-`pandas` implementation (vectorised code)\n",
    "\n",
    "The code below uses functionalities offered by `NEMOSIS`, `NEMSEER` and `pandas` to quickly calculate demand forecast error across a longer period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_p5min_demand_forecast_error_vectorised(\n",
    "    analysis_start: str, analysis_end: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculates P5MIN demand forecast error (Actual - Forecast) for all forecasts\n",
    "    that are run for a given forecasted_time in a vectorised fashion.\n",
    "\n",
    "    Args:\n",
    "        forecasted_time: Datetime string in the form YYYY/mm/dd HH:MM:SS\n",
    "    Returns:\n",
    "        pandas DataFrame with forecast error in `TOTALDEMAND` columns, the ahead time\n",
    "        of the forecast run in `ahead_time`, and the forecasted time in\n",
    "        `forecasted_time`.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_forecast_data(analysis_start: str, analysis_end: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Use NEMSEER to get 5MPD forecast data. Also omits any intervention periods.\n",
    "        \"\"\"\n",
    "        # use NEMSEER functions to compile pre-cached data\n",
    "        forecasts_run_start, forecasts_run_end = generate_runtimes(\n",
    "            analysis_start, analysis_end, \"P5MIN\"\n",
    "        )\n",
    "        forecast_df = compile_data(\n",
    "            forecasts_run_start,\n",
    "            forecasts_run_end,\n",
    "            analysis_start,\n",
    "            analysis_end,\n",
    "            \"P5MIN\",\n",
    "            \"REGIONSOLUTION\",\n",
    "            \"nemseer_cache/\",\n",
    "        )[\"REGIONSOLUTION\"]\n",
    "        # remove intervention periods\n",
    "        forecast_df = forecast_df.query(\"INTERVENTION == 0\")\n",
    "        return forecast_df\n",
    "\n",
    "    def get_actual_data(analysis_start: str, analysis_end: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Use NEMOSIS to get actual data. Also omits any intervention periods\n",
    "        \"\"\"\n",
    "        # NEMOSIS start time must precede end of interval of interest by 5 minutes\n",
    "        nemosis_start = (\n",
    "            datetime.strptime(analysis_start, DATETIME_FORMAT + \":%S\")\n",
    "            - timedelta(minutes=5)\n",
    "        ).strftime(DATETIME_FORMAT + \":%S\")\n",
    "        # use NEMOSIS to compile pre-cached data and filter out interventions\n",
    "        actual_df = nemosis.dynamic_data_compiler(\n",
    "            nemosis_start,\n",
    "            analysis_end,\n",
    "            \"DISPATCHREGIONSUM\",\n",
    "            nemosis_cache,\n",
    "            filter_cols=[\"INTERVENTION\"],\n",
    "            filter_values=([0],),\n",
    "            fformat=\"parquet\",\n",
    "        )\n",
    "        return actual_df\n",
    "\n",
    "    def calculate_p5min_forecast_demand_error(\n",
    "        actual_demand: pd.DataFrame, forecast_demand: pd.DataFrame\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Calculate P5MIN forecast demand error given actual and forecast demand\n",
    "\n",
    "        Ahead time calculation reflects the fact that P5MIN actual run time is\n",
    "        5 minutes before the nominal run time.\n",
    "        \"\"\"\n",
    "        # left merge ensures all forecasted values have the corresponding actual value merged in\n",
    "        merged = pd.merge(\n",
    "            forecast_demand, actual_demand, on=\"forecasted_time\", how=\"left\"\n",
    "        )\n",
    "        if len(merged) > len(forecast_demand):\n",
    "            raise ValueError(\n",
    "                \"Merge should return DataFrame with dimensions of forecast data\"\n",
    "            )\n",
    "        # subtract 5 minutes from run time to get actual run time\n",
    "        merged[\"ahead_time\"] = merged[\"forecasted_time\"] - (\n",
    "            merged[\"RUN_DATETIME\"] - timedelta(minutes=5)\n",
    "        )\n",
    "        forecast_error = (\n",
    "            merged[\"TOTALDEMAND\"] - merged[\"FORECAST_TOTALDEMAND\"]\n",
    "        ).rename(\"TOTALDEMAND\")\n",
    "        # create the forecast error DataFrame\n",
    "        forecast_error = pd.concat(\n",
    "            [forecast_error, merged[\"ahead_time\"]], axis=1\n",
    "        ).set_index(merged[\"forecasted_time\"])\n",
    "        return forecast_error\n",
    "\n",
    "    # get forecast data\n",
    "    forecast_df = get_forecast_data(analysis_start, analysis_end)\n",
    "    # rename columns in preparation for merge\n",
    "    forecast_df = forecast_df.rename(\n",
    "        columns={\n",
    "            \"TOTALDEMAND\": \"FORECAST_TOTALDEMAND\",\n",
    "            \"INTERVAL_DATETIME\": \"forecasted_time\",\n",
    "        }\n",
    "    )\n",
    "    # group by forecasted and run times, then sum demand across regions to get NEM-wide demand\n",
    "    forecast_demand = forecast_df.groupby([\"forecasted_time\", \"RUN_DATETIME\"])[\n",
    "        \"FORECAST_TOTALDEMAND\"\n",
    "    ].sum()\n",
    "    forecast_demand = forecast_demand.reset_index()\n",
    "\n",
    "    # get actual data\n",
    "    actual_df = get_actual_data(analysis_start, analysis_end)\n",
    "    # rename columns in preparation for merge\n",
    "    actual_df = actual_df.rename(\n",
    "        columns={\n",
    "            \"SETTLEMENTDATE\": \"forecasted_time\",\n",
    "            \"TOTALDEMAND\": \"TOTALDEMAND\",\n",
    "        }\n",
    "    )\n",
    "    # group by forecasted time and then sum demand across regions to get NEM-wide demand\n",
    "    actual_demand = (\n",
    "        actual_df.groupby(\"forecasted_time\")[\"TOTALDEMAND\"].sum().reset_index()\n",
    "    )\n",
    "\n",
    "    # calculate forecast error\n",
    "    forecast_error = calculate_p5min_forecast_demand_error(\n",
    "        actual_demand, forecast_demand\n",
    "    )\n",
    "    return forecast_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_error = calculate_p5min_demand_forecast_error_vectorised(\n",
    "    analysis_start, analysis_end\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting forecast error percentiles for each ahead time\n",
    "\n",
    "How does forecast error change based on how many minutes they are ahead of the time they are forecasting for?\n",
    "\n",
    "### Forecast error percentiles\n",
    "\n",
    "We can compute forecast error percentiles across `ahead_times` (between 0 and 55 minutes for 5-minute pre-dispatch).\n",
    "\n",
    "To do this, we will group the error DataFrame by `ahead_time`, compute the percentile and then add a column that indicates the computed percentile. We'll repeat this process across all percentiles of interest and then concatenate the results to form a single DataFrame for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_data = []\n",
    "for quantile in (0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99):\n",
    "    quantile_result = forecast_error.groupby(\n",
    "        forecast_error[\"ahead_time\"].dt.seconds / 60\n",
    "    )[\"TOTALDEMAND\"].quantile(quantile)\n",
    "    percentile_result = pd.concat(\n",
    "        [\n",
    "            quantile_result,\n",
    "            pd.Series(\n",
    "                np.repeat(quantile * 100, len(quantile_result)),\n",
    "                index=quantile_result.index,\n",
    "                name=\"percentile\",\n",
    "            ).astype(int),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    percentile_data.append(percentile_result)\n",
    "percentile_df = pd.concat(percentile_data, axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot these quantiles for each ahead time. \n",
    "\n",
    "It's interesting to note that there is only a slight positive bias in the 50th percentile forecast as the forecast ahead time approaches one hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ahead_percentile = px.line(\n",
    "    percentile_df,\n",
    "    x=\"ahead_time\",\n",
    "    y=\"TOTALDEMAND\",\n",
    "    color=\"percentile\",\n",
    "    title=\"5MPD NEM-wide Demand Forecast Error 2021 (Actual - Forecast)\",\n",
    "    labels={\n",
    "        \"TOTALDEMAND\": \"Demand Forecast Error (MW)\",\n",
    "        \"ahead_time\": \"Forecast Ahead Time (minutes)\",\n",
    "    },\n",
    ")\n",
    "ahead_percentile[\"layout\"][\"xaxis\"][\"autorange\"] = \"reversed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "pio.write_html(\n",
    "    ahead_percentile, \"../_static/p5min_error_2021_ahead_time_percentile.html\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{raw} html\n",
    "---\n",
    "file: ../_static/p5min_error_2021_ahead_time_percentile.html\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the distributions of forecast errors by ahead time\n",
    "\n",
    "We can look at the full distributions of forecast errors across ahead times. \n",
    "\n",
    "But first, we'll remove \"forecasts\" at `ahead_time` = 5, as these correspond to actual dispatch conditions.\n",
    "\n",
    "We'll also convert the Timedeltas into an integer, which will be helpful for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_797100/1463573992.py:2: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "error_excluding_real_time = forecast_error[\n",
    "    forecast_error[\"ahead_time\"].dt.seconds > 300\n",
    "]\n",
    "error_excluding_real_time.loc[:, \"ahead_time\"] = (\n",
    "    error_excluding_real_time.loc[:, \"ahead_time\"].dt.seconds / 60\n",
    ").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ahead_hist = px.histogram(\n",
    "    error_excluding_real_time, x=\"TOTALDEMAND\", color=\"ahead_time\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "pio.write_html(ahead_hist, \"../_static/p5min_error_2021_ahead_time_hists.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{raw} html\n",
    "---\n",
    "file: ../_static/p5min_error_2021_ahead_time_hists.html\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting forecast error quantiles against time of day\n",
    "\n",
    "How does forecast error change across the day?\n",
    "\n",
    "Below, we repeat percentile calculations, but this time we group the data by the time of day.\n",
    "\n",
    "From the chart below, we can see that, across the NEM, intra-hour demand forecasting errors tend to be larger during the morning and evening ramps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOD_percentile_data = []\n",
    "for quantile in (0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99):\n",
    "    quantile_result = error_excluding_real_time.groupby(\n",
    "        error_excluding_real_time.index.time\n",
    "    )[\"TOTALDEMAND\"].quantile(quantile)\n",
    "    percentile_result = pd.concat(\n",
    "        [\n",
    "            quantile_result,\n",
    "            pd.Series(\n",
    "                np.repeat(quantile * 100, len(quantile_result)),\n",
    "                index=quantile_result.index,\n",
    "                name=\"percentile\",\n",
    "            ).astype(int),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    TOD_percentile_data.append(percentile_result)\n",
    "TOD_percentile = pd.concat(TOD_percentile_data, axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tod_percentile = px.line(\n",
    "    TOD_percentile,\n",
    "    x=\"index\",\n",
    "    y=\"TOTALDEMAND\",\n",
    "    color=\"percentile\",\n",
    "    labels={\n",
    "        \"TOTALDEMAND\": \"Demand Forecast Error (MW)\",\n",
    "        \"ahead_time\": \"Forecast Ahead Time (minutes)\",\n",
    "        \"index\": \"Time of Day\",\n",
    "    },\n",
    "    title=\"5MPD NEM-wide Demand Forecast Error 2021 (Actual - Forecast,\"\n",
    "    + \" excludes forecast run at real time)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "pio.write_html(tod_percentile, \"../_static/p5min_error_2021_tod_percentile.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{raw} html\n",
    "---\n",
    "file: ../_static/p5min_error_2021_tod_percentile.html\n",
    "---\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemseer",
   "language": "python",
   "name": "nemseer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "mystnb": {
   "execution_mode": "off"
  },
  "vscode": {
   "interpreter": {
    "hash": "576fc7d7a7b34496c6e4e4b9ac6c058d3cc09d324fa720081ac27e023c8ef135"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
